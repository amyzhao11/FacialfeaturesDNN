{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19be54b-dcc7-48e7-a28c-09a2712bfa1f",
   "metadata": {},
   "source": [
    "# Extracting facial features using a facial recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a4600c-3aac-4ba1-8245-e234ce150052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to check that we are in the correct environment\n",
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "#you want to see something like (a directory that mentions the name of your environment)\n",
    "#C:\\ ... \\facestuff\\python.exe\n",
    "#if you aren't, go back to anaconda powershell prompt and activate the correct environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b53d9-eb98-4190-872e-730a6c0c6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import and install packages\n",
    "import tensorflow\n",
    "import keras\n",
    "!pip install pillow==9.4.0  \n",
    "!pip install keras_applications\n",
    "!pip install keras_vggface\n",
    "\n",
    "from keras import applications\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras_vggface.vggface import VGGFace\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.utils.image_utils import load_img, img_to_array\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "\n",
    "from keras_vggface import utils\n",
    "from keras.preprocessing import image\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a225116-cbb9-4be9-abca-dfb0337c891f",
   "metadata": {},
   "source": [
    "You may receive the following error that ends in the following line:\n",
    "```ModuleNotFoundError: No module named 'keras.engine.topology'```\n",
    "\n",
    "If you have received that error, you will need to do the following:\n",
    "Use file explorer and locate `C:\\...\\Anaconda3\\envs\\facestuff\\Lib\\site-packages\\keras_vggface`\n",
    "Find the file called \"models.py\" and open it using notepad or notepad++.\n",
    "\n",
    "Change line 20 from:\n",
    "`from keras.engine.topology import get_source_inputs`\n",
    "to:\n",
    "`from keras.utils.layer_utils import get_source_inputs`\n",
    "\n",
    "Rerun the code block above, and the error should go away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5e3ed-4aa7-4c30-a8e5-772dd898ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(x):\n",
    "    #x2=tf.nn.l2_normalize(x,axis=None,epsilon=1e-12,name=None,dim=None)\n",
    "    x2=tf.nn.l2_normalize(x,dim=1)\n",
    "    return x2\n",
    "\n",
    "\n",
    "# CHOOSE AN ARCHITECTURE:  \n",
    "architecture = 'vgg'\n",
    "SaveAs = 'VGG16'\n",
    "#architecture = 'resnet'\n",
    "#SaveAs = 'ResNet50'\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "if architecture == 'vgg':\n",
    "    #baseline model with vgg:\n",
    "    vgg_model = VGGFace(model = 'vgg16')\n",
    "#                        CHANGE LAYER HERE  \\/\n",
    "    feature_layer = vgg_model.get_layer('fc7/relu').output\n",
    "    model = Model(vgg_model.input, feature_layer)\n",
    "    version = 1 \n",
    "\n",
    "\n",
    "elif architecture == 'resnet':\n",
    "    #baseline model with resnet:\n",
    "    resnet = VGGFace(model = 'resnet50')\n",
    "    \n",
    "#                   CHANGE LAYER HERE  \\/\n",
    "    last_layer = resnet.get_layer('avg_pool').output\n",
    "    feature_layer = Flatten(name='flatten')(last_layer)\n",
    "    model = Model(resnet.input, feature_layer)\n",
    "    version = 2   \n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebabe45-4075-4013-817c-083e9bdbf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set folder directories\n",
    "folder = \"#######Where my images are saved######\"\n",
    "save_path = \"######Where I want to save my csv file######\"\n",
    "#list of all the image names\n",
    "list_dir = os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e13a5-7bd8-4d60-a818-3c6361c11721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show list of names\n",
    "list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44fe139-1104-45f9-90f3-7e1ea7609d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input image into model\n",
    "\n",
    "feature_vectors=[]\n",
    "for i in range(len(list_dir)):\n",
    "# for i in range(1):\n",
    "    array = preprocess_image(folder+list_dir[i])\n",
    "    img = vgg_face_descriptor.predict(array)[0,:]\n",
    "    img = img.reshape(-1)\n",
    "    feature_vectors.append(img)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df70aee-37a7-46ed-b722-f1b8bf4d5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save output\n",
    "np.savetxt(save_path +'extractfeatures'+ SaveAs + '_Feature_Vector_Final.csv', feature_vectors, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
